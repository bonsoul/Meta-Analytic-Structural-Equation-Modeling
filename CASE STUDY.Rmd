---
title: "PROJOJECT"
author: "Bonsoul"
date: "2025-08-19"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(readr)
library(dplyr)
library(tidyverse)
library(VIM)
library(naniar)
library(DataExplorer)
library(corrplot)
library(GGally)
library(skimr)
```

```{r}

df <- read_csv("psyco.csv")
colnames(df)
```

```{r}
str(df)
summary(df)

```

```{r}

# Assuming your dataset is already read into df
df <- df %>%
  # Fix age â†’ factor
  mutate(age = factor(age),
         gender = factor(gender),
         occupation = factor(occupation),
         line_of_work = factor(line_of_work),
         prefer = factor(prefer),
         certaindays_hw = factor(certaindays_hw)) %>%
  
  # Drop useless columns
  select(-`...20`, -`travel+work`) %>%
  
  # Rename confusing columns
  rename(time_bp = `time_bp...5`,
         time_bp2 = `time_bp...21`) %>%
  
  # Ensure numeric columns are numeric
  mutate(across(c(time_bp, time_dp, travel_time, easeof_online, home_env,
                  prod_inc, sleep_bal, new_skill, fam_connect, relaxed,
                  self_time), as.numeric)) %>%
  
  # Check for odd encodings in like_hw and dislike_hw
  mutate(like_hw = as.character(like_hw),
         dislike_hw = as.character(dislike_hw))

# Quick check
str(df)
summary(df)

```



```{r}
vis_miss(df)
skim(df)
```


```{r}
# Count total missing values in the dataset
sum(is.na(df))


# Percentage of missing values per column
colMeans(is.na(df)) * 100

```

```{r}
df1 <- df[, colSums(is.na(df)) < nrow(df)]
```


```{r}
categorical_vars <- c("gender", "occupation", "like_hw", "dislike_hw", "prefer")
for (var in categorical_vars) {
  print(
    ggplot(df1, aes(x = .data[[var]])) +
      geom_bar(fill = "steelblue") +
      theme_minimal() +
      ggtitle(paste("Distribution of", var))
  )
}
```


```{r}
# Select only numeric columns
numeric_df <- df1 %>% select(where(is.numeric))



numeric_df %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = value)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "white") +
  facet_wrap(~variable, scales = "free", ncol = 3) +
  theme_minimal()
```


```{r}
# 3. Boxplots for outlier detection
numeric_df %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "value") %>%
  ggplot(aes(y = value, x = variable, fill = variable)) +
  geom_boxplot(show.legend = FALSE, outlier.color = "red") +
  coord_flip() +
  theme_minimal()
```


```{r}
ggcorr(numeric_df, label = TRUE, label_round = 2, hjust = 0.75, size = 3)
```

```{r}
ggpairs(numeric_df)
```


```{r}
library(purrr)
library(Matrix)
library(matrixcalc)
library(metaSEM)
```

```{r}
vars <- c("time_bp", "sleep_bal", "prod_inc")  # X, M, Y (in that order)

# --- 2) Choose grouping variable to define "studies" ---
group_var <- "occupation"  
```


```{r}
dat <- df1 %>%
  select(all_of(c(group_var, vars))) %>%
  mutate(across(all_of(vars), as.numeric)) %>%
  filter(rowSums(is.na(across(all_of(vars)))) < length(vars))
```

```{r}
min_n <- 30  # you can relax/tighten this

by_group <- dat %>%
  group_by(.data[[group_var]]) %>%
  group_split()
```


```{r}
safe_cor <- function(d, varnames) {
  dsub <- d %>% select(all_of(varnames))
  # require enough rows and non-zero variance for all vars
  if (nrow(dsub) < min_n || any(apply(dsub, 2, function(x) sd(x, na.rm = TRUE) == 0))) return(NULL)
  cm <- cor(dsub, use = "pairwise.complete.obs")
  # ensure proper dimnames
  dimnames(cm) <- list(varnames, varnames)
  # must be symmetric & (near) positive definite; if not, smooth a bit
  if (!is.positive.definite(cm)) {
    cm_pd <- as.matrix(nearPD(cm)$mat)
    dimnames(cm_pd) <- list(varnames, varnames)
    return(cm_pd)
  }
  cm
}



cors_list <- map(by_group, ~ safe_cor(.x, vars))
ns_list   <- map_int(by_group, nrow)
```

```{r}
# Keep only valid studies (non-NULL cors, no NA entries)
keep_idx <- which(map_lgl(cors_list, ~ !is.null(.x) && !any(is.na(.x))))
cors     <- cors_list[keep_idx]
n_study  <- ns_list[keep_idx]
study_ids <- sapply(by_group[keep_idx], function(g) unique(g[[group_var]])[1])

if (length(cors) < 2) {
  stop("Not enough valid groups to run MASEM. Try lowering min_n or choosing another grouping variable.")
}

cat("Included studies (groups):\n")
print(study_ids)
cat("Sample sizes per study:\n")
print(n_study)
```

```{r}
# --- 5) Stage 1: Random-effects pooling of correlation matrices ---
stage1 <- tssem1(cors, n_study, method = "REM")
```

```{r}
# Manifest names MUST match 'vars' order: c("time_bp","sleep_bal","prod_inc")
model2 <- mxModel("Mediation_TSSEM",
  type = "RAM",
  manifestVars = vars,
  latentVars = NULL,
  # Paths
  mxPath(from = "time_bp",  to = "sleep_bal", arrows = 1, free = TRUE, values = 0.2, labels = "a"),
  mxPath(from = "sleep_bal", to = "prod_inc",  arrows = 1, free = TRUE, values = 0.2, labels = "b"),
  mxPath(from = "time_bp",   to = "prod_inc",  arrows = 1, free = TRUE, values = 0.2, labels = "c"),
  # Variances (disturbances)
  mxPath(from = vars, arrows = 2, free = TRUE, values = 1)
)

stage2 <- tssem2(stage1, model2, diag.constraints = FALSE)
out <- summary(stage2)
print(out)
```

```{r}
# Step 1: Create correlation matrix from numeric variables
numeric_vars <- c("time_bp", "time_dp", "travel_time",
                  "easeof_online", "home_env", "prod_inc", 
                  "sleep_bal", "new_skill", "fam_connect", 
                  "relaxed", "self_time", "time_bp2")

cor_matrix <- cor(df[, numeric_vars], use = "pairwise.complete.obs")
```

```{r}
# Step 2: Wrap as list (as if one study provided this correlation matrix)
cor_list <- list(cor_matrix)

# Step 3: Sample size
n_list <- nrow(df)

# Step 4: Random-effects meta-analysis of correlation matrices
stage1 <- tssem1(cor_list, n_list, method="REM")
```

```{r}
# Load packages
library(metaSEM)
library(lavaan)

# Step 1: Create correlation matrix from numeric variables
numeric_vars <- c("time_bp", "time_dp", "travel_time",
                  "easeof_online", "home_env", "prod_inc", 
                  "sleep_bal", "new_skill", "fam_connect", 
                  "relaxed", "self_time", "time_bp2")

cor_matrix <- cor(df[, numeric_vars], use = "pairwise.complete.obs")

# Step 2: Wrap as list (as if one study provided this correlation matrix)
cor_list <- list(cor_matrix)

# Step 3: Sample size
n_list <- nrow(df)

# Step 4: Random-effects meta-analysis of correlation matrices
stage1 <- tssem1(cor_list, n_list, method="REM")

# Step 5: Define structural model (example)
model2 <- "
  # measurement model (just example)
  WellBeing =~ sleep_bal + relaxed + self_time + fam_connect
  Productivity =~ prod_inc + easeof_online + new_skill + home_env

  # structural relations
  Productivity ~ WellBeing + travel_time + time_bp
"

# Step 6: Run stage 2 (SEM)
stage2 <- tssem2(stage1, model2, diag.constraints=FALSE)

# Step 7: Summary
summary(stage2)
 
```

```{r}
library(lavaan)

model2 <- "
  WellBeing =~ sleep_bal + relaxed + self_time + fam_connect
  Productivity =~ prod_inc + easeof_online + new_skill + home_env

  Productivity ~ WellBeing + travel_time + time_bp
"

fit <- sem(model2, data = df, estimator="ML")
summary(fit, fit.measures=TRUE, standardized=TRUE)

```


```{r}
# Inspect modification indices (to see if adding extra paths would improve fit)
modificationindices(fit, sort.=TRUE, maximum.number=10)

# Visualize SEM path diagram
library(semPlot)
semPaths(fit, "std", layout="tree", residuals=TRUE, 
         intercepts=FALSE, edge.label.cex=0.8)

```


